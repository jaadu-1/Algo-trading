{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 12369073,
          "sourceType": "datasetVersion",
          "datasetId": 7798779
        }
      ],
      "dockerImageVersionId": 31040,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Product_!",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaadu-1/Algo-trading/blob/main/Product_!.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "GI19B9JwuTAc"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "krish39696_product_track_path = kagglehub.dataset_download('krish39696/product-track')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "d-HimoTNuTAg"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load offer data\n",
        "offer_df = pd.read_parquet('/kaggle/input/product-track/amex_offers_data.parquet')  # Adjust path as needed\n",
        "\n",
        "# Preview\n",
        "offer_df.head()\n",
        "offer_df.info()\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-04T07:41:14.465902Z",
          "iopub.execute_input": "2025-07-04T07:41:14.466211Z",
          "iopub.status.idle": "2025-07-04T07:41:21.328822Z",
          "shell.execute_reply.started": "2025-07-04T07:41:14.466189Z",
          "shell.execute_reply": "2025-07-04T07:41:21.328132Z"
        },
        "id": "Lvmt6p8TuTAg",
        "outputId": "79811cf3-6dbe-4df9-8bd9-20f3b57e30ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 2004812 entries, 0 to 2004811\nData columns (total 55 columns):\n #   Column        Dtype \n---  ------        ----- \n 0   customer_id   object\n 1   offer_id      object\n 2   event_ts      object\n 3   event_dt      object\n 4   offer_action  object\n 5   var_1         object\n 6   var_2         object\n 7   var_3         object\n 8   var_4         object\n 9   var_5         object\n 10  var_6         object\n 11  var_7         object\n 12  var_8         object\n 13  var_9         object\n 14  var_10        object\n 15  var_11        object\n 16  var_12        object\n 17  var_13        object\n 18  var_14        object\n 19  var_15        object\n 20  var_16        object\n 21  var_17        object\n 22  var_18        object\n 23  var_19        object\n 24  var_20        object\n 25  var_21        object\n 26  var_22        object\n 27  var_23        object\n 28  var_24        object\n 29  var_25        object\n 30  var_26        object\n 31  var_27        object\n 32  var_28        object\n 33  var_29        object\n 34  var_30        object\n 35  var_31        object\n 36  var_32        object\n 37  var_33        object\n 38  var_34        object\n 39  var_35        object\n 40  var_36        object\n 41  var_37        object\n 42  var_38        object\n 43  var_39        object\n 44  var_40        object\n 45  var_41        object\n 46  var_42        object\n 47  var_43        object\n 48  var_44        object\n 49  var_45        object\n 50  var_46        object\n 51  var_47        object\n 52  var_48        object\n 53  var_49        object\n 54  var_50        object\ndtypes: object(55)\nmemory usage: 841.3+ MB\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "offer_df.columns\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-04T07:01:09.038953Z",
          "iopub.execute_input": "2025-07-04T07:01:09.039258Z",
          "iopub.status.idle": "2025-07-04T07:01:09.046425Z",
          "shell.execute_reply.started": "2025-07-04T07:01:09.039234Z",
          "shell.execute_reply": "2025-07-04T07:01:09.045535Z"
        },
        "id": "-QWtejDzuTAh",
        "outputId": "fb329512-bb80-43fb-b0e6-025f7cc42a7b"
      },
      "outputs": [
        {
          "execution_count": 2,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Index(['customer_id', 'offer_id', 'event_ts', 'event_dt', 'offer_action',\n       'var_1', 'var_2', 'var_3', 'var_4', 'var_5', 'var_6', 'var_7', 'var_8',\n       'var_9', 'var_10', 'var_11', 'var_12', 'var_13', 'var_14', 'var_15',\n       'var_16', 'var_17', 'var_18', 'var_19', 'var_20', 'var_21', 'var_22',\n       'var_23', 'var_24', 'var_25', 'var_26', 'var_27', 'var_28', 'var_29',\n       'var_30', 'var_31', 'var_32', 'var_33', 'var_34', 'var_35', 'var_36',\n       'var_37', 'var_38', 'var_39', 'var_40', 'var_41', 'var_42', 'var_43',\n       'var_44', 'var_45', 'var_46', 'var_47', 'var_48', 'var_49', 'var_50'],\n      dtype='object')"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load data\n",
        "df = pd.read_parquet('/kaggle/input/product-track/amex_offers_data.parquet')\n",
        "submission = pd.read_csv('/kaggle/input/product-track/6855142f07670_submission_template.csv')  # still used, not saved\n",
        "\n",
        "# -------------------------------\n",
        "# Step 1: Clean Dates\n",
        "# -------------------------------\n",
        "df['event_dt'] = pd.to_datetime(df['event_dt'], errors='coerce', infer_datetime_format=True)\n",
        "\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# Step 2: Convert important variables to numeric\n",
        "# -------------------------------\n",
        "vars_to_convert = [\n",
        "    'var_9',  # airline interest\n",
        "    'var_20', 'var_27', 'var_50',  # airline/travel spend indicators\n",
        "    'var_31',  # clicked\n",
        "    'var_32',  # min spend for DOE\n",
        "    'var_34',  # discount value\n",
        "    'var_36',  # reward points per dollar\n",
        "    'var_37', 'var_38', 'var_39', 'var_40', 'var_41', 'var_42', 'var_43'  # CTR-related\n",
        "]\n",
        "\n",
        "for col in vars_to_convert:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "# -------------------------------\n",
        "# Step 3: Flags and Derived Columns\n",
        "# -------------------------------\n",
        "df['is_clicked'] = df['var_31'].fillna(0).astype(int)\n",
        "df['discount_value'] = df['var_34']\n",
        "\n",
        "# Airline-related offer flag\n",
        "df['is_airline_offer'] = (\n",
        "    (df['var_9'] > 0.5) |\n",
        "    (df['var_20'] > 0) |\n",
        "    (df['var_27'] > 0) |\n",
        "    (df['var_50'] == 1)\n",
        ").astype(int)\n",
        "\n",
        "# -------------------------------\n",
        "# Step 4: Define Active Users (30+ days span)\n",
        "# -------------------------------\n",
        "user_activity = df.groupby('customer_id')['event_dt'].agg(['min', 'max']).reset_index()\n",
        "user_activity['active_days'] = (user_activity['max'] - user_activity['min']).dt.days\n",
        "user_activity['is_active'] = user_activity['active_days'] >= 5\n",
        "\n",
        "# Merge activity flag\n",
        "df = df.merge(user_activity[['customer_id', 'is_active']], on='customer_id', how='left')\n",
        "\n",
        "# -------------------------------\n",
        "# Step 5: Q1.1 - Are active users more likely to choose airline offers?\n",
        "# -------------------------------\n",
        "active_df = df[df['is_active'] == True]\n",
        "airline_ctr = active_df[active_df['is_airline_offer'] == 1]['is_clicked'].mean()\n",
        "non_airline_ctr = active_df[active_df['is_airline_offer'] == 0]['is_clicked'].mean()\n",
        "q1_1 = 'TRUE' if airline_ctr > non_airline_ctr else 'FALSE'\n",
        "\n",
        "# -------------------------------\n",
        "# Step 6: Q1.2 - Do active users save more from discounts?\n",
        "# -------------------------------\n",
        "active_discount = active_df[active_df['is_clicked'] == 1]['discount_value'].mean()\n",
        "inactive_discount = df[(df['is_active'] == False) & (df['is_clicked'] == 1)]['discount_value'].mean()\n",
        "q1_2 = 'TRUE' if active_discount > inactive_discount else 'FALSE'\n",
        "\n",
        "# -------------------------------\n",
        "# Step 7: Q1.3 - Unique active users who clicked on airline offers\n",
        "# -------------------------------\n",
        "q1_3 = df[(df['is_active']) & (df['is_clicked'] == 1) & (df['is_airline_offer'] == 1)]['customer_id'].nunique()\n",
        "\n",
        "# -------------------------------\n",
        "# Step 8: Print Results\n",
        "# -------------------------------\n",
        "print(f\"Q1.1 ➤ Active users more likely to choose airline offers? → {q1_1}\")\n",
        "print(f\"Q1.2 ➤ Active users save more from discounts? → {q1_2}\")\n",
        "print(f\"Q1.3 ➤ Unique active users who clicked airline offers → {q1_3}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-04T07:41:21.330029Z",
          "iopub.execute_input": "2025-07-04T07:41:21.330369Z",
          "iopub.status.idle": "2025-07-04T07:41:45.980489Z",
          "shell.execute_reply.started": "2025-07-04T07:41:21.330348Z",
          "shell.execute_reply": "2025-07-04T07:41:45.979682Z"
        },
        "id": "FQao3_vguTAh",
        "outputId": "478fa3c9-1606-4425-829c-e9aae3dc1aad"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_35/4176316250.py:11: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n  df['event_dt'] = pd.to_datetime(df['event_dt'], errors='coerce', infer_datetime_format=True)\n/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Q1.1 ➤ Active users more likely to choose airline offers? → TRUE\nQ1.2 ➤ Active users save more from discounts? → TRUE\nQ1.3 ➤ Unique active users who clicked airline offers → 2688\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for col in ['var_48', 'var_49', 'var_50']:\n",
        "    df_q2[col] = pd.to_numeric(df_q2[col], errors='coerce').fillna(0).astype(int)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-04T07:42:53.001388Z",
          "iopub.execute_input": "2025-07-04T07:42:53.001957Z",
          "iopub.status.idle": "2025-07-04T07:42:53.026755Z",
          "shell.execute_reply.started": "2025-07-04T07:42:53.001928Z",
          "shell.execute_reply": "2025-07-04T07:42:53.025653Z"
        },
        "id": "WfcJ7pwfuTAi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Services offers:\", df_q2['var_48'].sum())\n",
        "print(\"Shopping offers:\", df_q2['var_49'].sum())\n",
        "print(\"Travel offers:\", df_q2['var_50'].sum())\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-04T07:43:48.756439Z",
          "iopub.execute_input": "2025-07-04T07:43:48.757099Z",
          "iopub.status.idle": "2025-07-04T07:43:48.764906Z",
          "shell.execute_reply.started": "2025-07-04T07:43:48.757071Z",
          "shell.execute_reply": "2025-07-04T07:43:48.764065Z"
        },
        "id": "V1SbTRj7uTAj",
        "outputId": "66df9f43-9edb-41e9-d6a9-b38625ab3b19"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Services offers: 103709\nShopping offers: 785022\nTravel offers: 76924\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "travel_df = df_q2[df_q2['var_50'] == 1]\n",
        "\n",
        "high_group = travel_df[travel_df['var_37'] >= df_q2['var_37'].median()]\n",
        "low_group = travel_df[travel_df['var_37'] < df_q2['var_37'].median()]\n",
        "\n",
        "print(\"Travel High Group CTR:\", high_group['var_31'].mean())\n",
        "print(\"Travel Low Group CTR:\", low_group['var_31'].mean())\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-04T07:44:35.304456Z",
          "iopub.execute_input": "2025-07-04T07:44:35.304751Z",
          "iopub.status.idle": "2025-07-04T07:44:35.465946Z",
          "shell.execute_reply.started": "2025-07-04T07:44:35.30473Z",
          "shell.execute_reply": "2025-07-04T07:44:35.464994Z"
        },
        "id": "_ndsPdVsuTAj",
        "outputId": "701b28c3-10d5-4e1a-caf2-58c2829b8199"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Travel High Group CTR: 1.0\nTravel Low Group CTR: 1.0\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Travel total:\", len(travel_df))\n",
        "print(\"High group count:\", len(high_group))\n",
        "print(\"Low group count:\", len(low_group))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-04T07:46:00.375723Z",
          "iopub.execute_input": "2025-07-04T07:46:00.376061Z",
          "iopub.status.idle": "2025-07-04T07:46:00.381466Z",
          "shell.execute_reply.started": "2025-07-04T07:46:00.376034Z",
          "shell.execute_reply": "2025-07-04T07:46:00.380437Z"
        },
        "id": "McPCyaR_uTAk",
        "outputId": "dda47f4f-d554-4457-9a28-4994cd4b8d03"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Travel total: 76924\nHigh group count: 75021\nLow group count: 1903\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Unique click values in travel group:\", travel_df['var_31'].unique())\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-04T07:46:13.552625Z",
          "iopub.execute_input": "2025-07-04T07:46:13.553575Z",
          "iopub.status.idle": "2025-07-04T07:46:13.559342Z",
          "shell.execute_reply.started": "2025-07-04T07:46:13.553537Z",
          "shell.execute_reply": "2025-07-04T07:46:13.558529Z"
        },
        "id": "d-rzMkRSuTAk",
        "outputId": "4ec2c840-05fb-48e9-97df-0b5975a6ff29"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Unique click values in travel group: [ 1. nan]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Ensure columns are numeric and clean\n",
        "df['var_31'] = pd.to_numeric(df['var_31'], errors='coerce').fillna(0).astype(int)\n",
        "df['var_37'] = pd.to_numeric(df['var_37'], errors='coerce')\n",
        "\n",
        "for col in ['var_48', 'var_49', 'var_50']:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
        "\n",
        "# Filter data for non-zero valid discount value per dollar and valid click values\n",
        "df_q2 = df[\n",
        "    df['var_37'].notna() &\n",
        "    (df['var_37'] > 0) &\n",
        "    (df['var_31'].isin([0, 1]))\n",
        "].copy()\n",
        "\n",
        "# Calculate median of discount per dollar (50th percentile)\n",
        "discount_median = df_q2['var_37'].median()\n",
        "\n",
        "# Label offers into high/low discount-per-dollar buckets\n",
        "df_q2['disc_value_group'] = np.where(df_q2['var_37'] >= discount_median, 'high', 'low')\n",
        "\n",
        "# Set up category mapping\n",
        "category_map = {\n",
        "    'var_48': 'Services',\n",
        "    'var_49': 'Shopping',\n",
        "    'var_50': 'Travel'\n",
        "}\n",
        "\n",
        "q2_results = {}\n",
        "\n",
        "# Loop over each offer category\n",
        "for var, category_name in category_map.items():\n",
        "    cat_df = df_q2[df_q2[var] == 1]\n",
        "\n",
        "    if cat_df.empty:\n",
        "        q2_results[category_name] = 0.000\n",
        "        continue\n",
        "\n",
        "    high_ctr = cat_df[cat_df['disc_value_group'] == 'high']['var_31'].mean()\n",
        "    low_ctr = cat_df[cat_df['disc_value_group'] == 'low']['var_31'].mean()\n",
        "\n",
        "    ctr_diff = np.floor((high_ctr - low_ctr) * 1000) / 1000  # floor to 3 decimals\n",
        "    q2_results[category_name] = ctr_diff\n",
        "\n",
        "# Print final results\n",
        "print(\"Q2 ➤ CTR Difference (High Discount - Low Discount):\")\n",
        "for category, diff in q2_results.items():\n",
        "    print(f\"{category}: {diff}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-04T07:48:02.565171Z",
          "iopub.execute_input": "2025-07-04T07:48:02.565489Z",
          "iopub.status.idle": "2025-07-04T07:48:07.12729Z",
          "shell.execute_reply.started": "2025-07-04T07:48:02.565468Z",
          "shell.execute_reply": "2025-07-04T07:48:07.1264Z"
        },
        "id": "gkcIbLG3uTAk",
        "outputId": "4c6f7d10-fdef-49c9-8b61-1e77e5e82e1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Q2 ➤ CTR Difference (High Discount - Low Discount):\nServices: 0.002\nShopping: -0.024\nTravel: -0.008\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert all relevant columns to numeric\n",
        "spend_cols = ['var_17', 'var_18', 'var_19', 'var_31', 'var_36']\n",
        "for col in spend_cols:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "# Step 1: Calculate Max Spend per Customer\n",
        "df['max_spend'] = df[['var_17', 'var_18', 'var_19']].max(axis=1)\n",
        "\n",
        "# Step 2: Get Customer-Level Spend (take max_spend per customer)\n",
        "customer_spend = df.groupby('customer_id')['max_spend'].max().dropna()\n",
        "\n",
        "# Step 3: Split into 3 equal segments\n",
        "quantiles = customer_spend.quantile([1/3, 2/3])\n",
        "low_thres = quantiles[1/3]\n",
        "high_thres = quantiles[2/3]\n",
        "\n",
        "def label_segment(spend):\n",
        "    if spend <= low_thres:\n",
        "        return 'LOW'\n",
        "    elif spend <= high_thres:\n",
        "        return 'MEDIUM'\n",
        "    else:\n",
        "        return 'HIGH'\n",
        "\n",
        "customer_segments = customer_spend.apply(label_segment).reset_index()\n",
        "customer_segments.columns = ['customer_id', 'segment']\n",
        "\n",
        "# Merge segment info back to original df\n",
        "df_q3 = df.merge(customer_segments, on='customer_id', how='inner')\n",
        "\n",
        "# Step 4.1: Avg reward point/dollar (var_36) for offers shown\n",
        "avg_reward_offered = df_q3.groupby('segment')['var_36'].mean().round(3)\n",
        "\n",
        "# Step 4.2: Avg reward point/dollar for offers clicked\n",
        "clicked = df_q3[df_q3['var_31'] == 1]\n",
        "avg_reward_clicked = clicked.groupby('segment')['var_36'].mean().round(3)\n",
        "\n",
        "# Step 4.3: Participation Rate = clicks / shown\n",
        "click_rate = df_q3.groupby('segment')['var_31'].mean().round(3)\n",
        "\n",
        "# Step 5: Find best performing segment\n",
        "best_segment = click_rate.idxmax()\n",
        "\n",
        "# Output everything\n",
        "print(\"Q3.1 ➤ Avg Reward Point per Dollar (Offers Shown):\")\n",
        "print(avg_reward_offered)\n",
        "print(\"\\nQ3.2 ➤ Avg Reward Point per Dollar (Offers Clicked):\")\n",
        "print(avg_reward_clicked)\n",
        "print(\"\\nQ3.3 ➤ Best Performing Segment (based on click rate):\", best_segment)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-04T07:49:35.933329Z",
          "iopub.execute_input": "2025-07-04T07:49:35.933909Z",
          "iopub.status.idle": "2025-07-04T07:49:44.145157Z",
          "shell.execute_reply.started": "2025-07-04T07:49:35.933882Z",
          "shell.execute_reply": "2025-07-04T07:49:44.144397Z"
        },
        "id": "2w8JhjCkuTAl",
        "outputId": "1092bb0f-4de6-4710-def6-0d97b6ac79d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Q3.1 ➤ Avg Reward Point per Dollar (Offers Shown):\nsegment\nHIGH      12.789\nLOW       12.786\nMEDIUM    12.838\nName: var_36, dtype: float64\n\nQ3.2 ➤ Avg Reward Point per Dollar (Offers Clicked):\nsegment\nHIGH      12.084\nLOW       10.375\nMEDIUM    11.389\nName: var_36, dtype: float64\n\nQ3.3 ➤ Best Performing Segment (based on click rate): LOW\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime, timedelta\n",
        "\n",
        "# 1. Filter data up to 7th Nov 2023\n",
        "cutoff_date = pd.to_datetime(\"2023-11-07\")\n",
        "df['event_dt'] = pd.to_datetime(df['event_dt'], errors='coerce')\n",
        "df_q4 = df[df['event_dt'] <= cutoff_date].copy()\n",
        "\n",
        "# 2. Calculate CTR per offer_id\n",
        "offer_stats = df_q4.groupby('offer_id').agg(\n",
        "    views=('var_31', 'count'),\n",
        "    clicks=('var_31', 'sum')\n",
        ")\n",
        "offer_stats['ctr'] = offer_stats['clicks'] / offer_stats['views']\n",
        "\n",
        "# 3. Only consider offers with above-average views\n",
        "avg_views = offer_stats['views'].mean()\n",
        "top_offers = offer_stats[offer_stats['views'] > avg_views].sort_values('ctr', ascending=False).head(10)\n",
        "top_offer_ids = top_offers.index.tolist()\n",
        "\n",
        "print(\"Top 10 Offer IDs:\", top_offer_ids)\n",
        "\n",
        "# 4. Map Offer ID to Offer Category (pick first category column with 1)\n",
        "category_cols = ['var_44', 'var_45', 'var_46', 'var_47', 'var_48', 'var_49', 'var_50']\n",
        "category_names = {\n",
        "    'var_44': 'Business',\n",
        "    'var_45': 'Dining',\n",
        "    'var_46': 'Entertainment',\n",
        "    'var_47': 'Retail',\n",
        "    'var_48': 'Services',\n",
        "    'var_49': 'Shopping',\n",
        "    'var_50': 'Travel'\n",
        "}\n",
        "\n",
        "top_offers_df = df_q4[df_q4['offer_id'].isin(top_offer_ids)].copy()\n",
        "\n",
        "def get_offer_category(row):\n",
        "    for var in category_cols:\n",
        "        if pd.to_numeric(row.get(var, 0), errors='coerce') == 1:\n",
        "            return category_names[var]\n",
        "    return \"Unknown\"\n",
        "\n",
        "top_offers_df['offer_category'] = top_offers_df.apply(get_offer_category, axis=1)\n",
        "offer_categories = top_offers_df.groupby('offer_id')['offer_category'].first()\n",
        "\n",
        "# 5. Average 3-month spend of users who clicked these offers\n",
        "top_clicks = top_offers_df[top_offers_df['var_31'] == 1].copy()\n",
        "top_clicks['3m_spend'] = top_clicks[['var_17', 'var_18', 'var_19']].max(axis=1)\n",
        "avg_spend = top_clicks.groupby('offer_id')['3m_spend'].mean().mean()\n",
        "avg_spend = np.floor(avg_spend * 1000) / 1000\n",
        "\n",
        "# 6. Calculate CTR in last 30 days before 7th Nov 2023 (i.e., since 8th Oct 2023)\n",
        "recent_start = cutoff_date - timedelta(days=30)\n",
        "recent_df = df[\n",
        "    df['offer_id'].isin(top_offer_ids) &\n",
        "    (df['event_dt'] >= recent_start) &\n",
        "    (df['event_dt'] <= cutoff_date)\n",
        "].copy()\n",
        "\n",
        "recent_ctr = recent_df.groupby('offer_id')['var_31'].mean().round(3)\n",
        "\n",
        "# Final output\n",
        "print(\"\\nQ4.1 ➤ Top 10 Offer ID : Offer Category Mapping\")\n",
        "for oid in top_offer_ids:\n",
        "    print(f\"{oid}: {offer_categories.get(oid, 'Unknown')}\")\n",
        "\n",
        "print(f\"\\nQ4.2 ➤ Average 3-Month Spend for these offers: {avg_spend}\")\n",
        "\n",
        "print(\"\\nQ4.3 ➤ Offer ID : 30-day CTR Mapping\")\n",
        "for oid in top_offer_ids:\n",
        "    print(f\"{oid}: {recent_ctr.get(oid, 0.000)}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-04T07:52:56.361396Z",
          "iopub.execute_input": "2025-07-04T07:52:56.361741Z",
          "iopub.status.idle": "2025-07-04T07:52:59.949425Z",
          "shell.execute_reply.started": "2025-07-04T07:52:56.361718Z",
          "shell.execute_reply": "2025-07-04T07:52:59.948586Z"
        },
        "id": "1tUjj1OquTAl",
        "outputId": "a57aed8d-e476-46c9-fea1-fc02124b0ec1"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Top 10 Offer IDs: ['760457', '498907', '313795', '72053', '82025', '23311', '7337', '26175', '331980', '26379']\n\nQ4.1 ➤ Top 10 Offer ID : Offer Category Mapping\n760457: Unknown\n498907: Travel\n313795: Travel\n72053: Shopping\n82025: Travel\n23311: Shopping\n7337: Shopping\n26175: Dining\n331980: Shopping\n26379: Shopping\n\nQ4.2 ➤ Average 3-Month Spend for these offers: 3853.782\n\nQ4.3 ➤ Offer ID : 30-day CTR Mapping\n760457: 0.168\n498907: 0.153\n313795: 0.145\n72053: 0.14\n82025: 0.138\n23311: 0.126\n7337: 0.117\n26175: 0.115\n331980: 0.111\n26379: 0.11\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Filter records as of 14th Nov 2023 (last 30 days window)\n",
        "cutoff_q5 = pd.to_datetime(\"2023-11-14\")\n",
        "df['event_dt'] = pd.to_datetime(df['event_dt'], errors='coerce')\n",
        "df_q5 = df[\n",
        "    (df['event_dt'] <= cutoff_q5) &\n",
        "    (df['event_dt'] >= cutoff_q5 - pd.Timedelta(days=30)) &\n",
        "    (pd.to_numeric(df['var_14'], errors='coerce').fillna(0) > 0)  # participated in email\n",
        "].copy()\n",
        "\n",
        "# Step 2: Type casting\n",
        "df_q5['var_31'] = pd.to_numeric(df_q5['var_31'], errors='coerce').fillna(0).astype(int)\n",
        "df_q5['var_14'] = pd.to_numeric(df_q5['var_14'], errors='coerce')\n",
        "df_q5['var_15'] = pd.to_numeric(df_q5['var_15'], errors='coerce')\n",
        "df_q5['var_13'] = pd.to_numeric(df_q5['var_13'], errors='coerce')\n",
        "\n",
        "# Step 3: Customer-level stats\n",
        "cust_stats = df_q5.groupby('customer_id').agg(\n",
        "    total_clicks=('var_31', 'sum'),\n",
        "    total_views=('var_31', 'count'),\n",
        "    channels=('var_13', 'max'),\n",
        "    email_sent=('var_14', 'max'),\n",
        "    email_clicks=('var_15', 'max')\n",
        ")\n",
        "\n",
        "cust_stats['offer_ctr'] = cust_stats['total_clicks'] / cust_stats['total_views']\n",
        "top15_customers = cust_stats.sort_values('offer_ctr', ascending=False).head(15)\n",
        "\n",
        "# Step 4: For each of top 15, get:\n",
        "# - Clicks per channel\n",
        "# - Email CTR\n",
        "# - Top offer category\n",
        "top15_ids = top15_customers.index.tolist()\n",
        "df_top15 = df_q5[df_q5['customer_id'].isin(top15_ids)].copy()\n",
        "\n",
        "# Category mapping\n",
        "category_cols = ['var_44', 'var_45', 'var_46', 'var_47', 'var_48', 'var_49', 'var_50']\n",
        "category_names = {\n",
        "    'var_44': 'Business',\n",
        "    'var_45': 'Dining',\n",
        "    'var_46': 'Entertainment',\n",
        "    'var_47': 'Retail',\n",
        "    'var_48': 'Services',\n",
        "    'var_49': 'Shopping',\n",
        "    'var_50': 'Travel'\n",
        "}\n",
        "\n",
        "# Determine top-performing category per customer based on offer clicks\n",
        "df_top15['clicked'] = df_top15['var_31'] == 1\n",
        "\n",
        "def get_top_category(group):\n",
        "    cat_clicks = {}\n",
        "    for col in category_cols:\n",
        "        cat_clicks[col] = group[group[col] == 1]['clicked'].sum()\n",
        "    top_col = max(cat_clicks, key=cat_clicks.get)\n",
        "    return category_names[top_col]\n",
        "\n",
        "top_categories = df_top15.groupby('customer_id').apply(get_top_category)\n",
        "\n",
        "# Final outputs:\n",
        "print(\"Q5.1 ➤ CustomerID : Offer Clicks per Channel Ratio\")\n",
        "for cid in top15_ids:\n",
        "    clicks = top15_customers.loc[cid, 'total_clicks']\n",
        "    channels = top15_customers.loc[cid, 'channels']\n",
        "    ratio = np.floor((clicks / channels) * 1000) / 1000 if channels > 0 else 0.0\n",
        "    print(f\"{cid}: {ratio}\")\n",
        "\n",
        "print(\"\\nQ5.2 ➤ CustomerID : Top Performing Offer Category\")\n",
        "for cid in top15_ids:\n",
        "    print(f\"{cid}: {top_categories[cid]}\")\n",
        "\n",
        "print(\"\\nQ5.3 ➤ CustomerID : Email CTR (Email Clicks / Sent)\")\n",
        "for cid in top15_ids:\n",
        "    sent = top15_customers.loc[cid, 'email_sent']\n",
        "    clicked = top15_customers.loc[cid, 'email_clicks']\n",
        "    ratio = np.floor((clicked / sent) * 1000) / 1000 if sent > 0 else 0.0\n",
        "    print(f\"{cid}: {ratio}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-04T07:55:29.026785Z",
          "iopub.execute_input": "2025-07-04T07:55:29.027138Z",
          "iopub.status.idle": "2025-07-04T07:55:34.393218Z",
          "shell.execute_reply.started": "2025-07-04T07:55:29.027102Z",
          "shell.execute_reply": "2025-07-04T07:55:34.392271Z"
        },
        "id": "2bXE0PIAuTAl",
        "outputId": "04361d45-b18e-4f36-d70b-c539961433b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Q5.1 ➤ CustomerID : Offer Clicks per Channel Ratio\n1686517: 16.23\n1674697: 0.45\n1521739: 0.126\n1407212: 0.103\n1672300: 2.194\n1006105: 0.68\n1391327: 0.0\n1077553: 2.075\n1683309: 2.695\n1846042: 1.288\n1500394: 123.0\n1313065: 6.0\n1282059: 0.787\n1598859: 2.75\n1207550: 15.666\n\nQ5.2 ➤ CustomerID : Top Performing Offer Category\n1686517: Shopping\n1674697: Shopping\n1521739: Travel\n1407212: Shopping\n1672300: Shopping\n1006105: Shopping\n1391327: Shopping\n1077553: Shopping\n1683309: Shopping\n1846042: Shopping\n1500394: Shopping\n1313065: Shopping\n1282059: Shopping\n1598859: Shopping\n1207550: Shopping\n\nQ5.3 ➤ CustomerID : Email CTR (Email Clicks / Sent)\n1686517: nan\n1674697: nan\n1521739: nan\n1407212: 1.6\n1672300: nan\n1006105: nan\n1391327: nan\n1077553: nan\n1683309: nan\n1846042: nan\n1500394: nan\n1313065: nan\n1282059: nan\n1598859: 1.25\n1207550: nan\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_35/959145475.py:57: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  top_categories = df_top15.groupby('customer_id').apply(get_top_category)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure datetime is correct\n",
        "df['event_dt'] = pd.to_datetime(df['event_dt'], errors='coerce')\n",
        "df['var_14'] = pd.to_numeric(df['var_14'], errors='coerce').fillna(0)\n",
        "df['var_15'] = pd.to_numeric(df['var_15'], errors='coerce').fillna(0)\n",
        "df['var_31'] = pd.to_numeric(df['var_31'], errors='coerce').fillna(0)\n",
        "\n",
        "# Sort data per user over time\n",
        "df_q6 = df.sort_values(['customer_id', 'event_dt'])\n",
        "\n",
        "# Step 1 ➤ Compute EWMA per customer per date\n",
        "def compute_ewma_click_prob(group):\n",
        "    return group['var_31'].ewm(alpha=0.5).mean()\n",
        "\n",
        "df_q6['ewma_click_prob'] = df_q6.groupby('customer_id').apply(compute_ewma_click_prob).reset_index(level=0, drop=True)\n",
        "\n",
        "# Step 2 ➤ P(Click | Email Sent)\n",
        "# We filter only rows where email was sent\n",
        "email_sent_df = df_q6[df_q6['var_14'] > 0]\n",
        "p_click_given_email = np.floor(email_sent_df['ewma_click_prob'].mean() * 1000) / 1000\n",
        "\n",
        "# Step 3 ➤ P(Click | Clicked in Past)\n",
        "# We filter rows where past click count > 0 (rolling clicks)\n",
        "past_click_df = df_q6.groupby('customer_id')['var_31'].cumsum()\n",
        "clicked_before_df = df_q6[past_click_df > 0]\n",
        "p_click_given_past = np.floor(clicked_before_df['ewma_click_prob'].mean() * 1000) / 1000\n",
        "\n",
        "# Print results\n",
        "print(\"Q6.1 ➤ P(Click | Email Offer Sent):\", p_click_given_email)\n",
        "print(\"Q6.2 ➤ P(Click | Clicked in Past):\", p_click_given_past)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-04T07:57:34.390883Z",
          "iopub.execute_input": "2025-07-04T07:57:34.391226Z",
          "iopub.status.idle": "2025-07-04T07:57:44.533996Z",
          "shell.execute_reply.started": "2025-07-04T07:57:34.391205Z",
          "shell.execute_reply": "2025-07-04T07:57:44.533288Z"
        },
        "id": "TWfRnhFXuTAm",
        "outputId": "9783a913-76e2-4f89-8a5d-7c7d2e574d06"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_35/3846757762.py:14: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  df_q6['ewma_click_prob'] = df_q6.groupby('customer_id').apply(compute_ewma_click_prob).reset_index(level=0, drop=True)\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Q6.1 ➤ P(Click | Email Offer Sent): 0.047\nQ6.2 ➤ P(Click | Clicked in Past): 0.095\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load submission template\n",
        "template_path = \"/kaggle/input/product-track/6855142f07670_submission_template.csv\"\n",
        "submission = pd.read_csv(template_path, encoding=\"ISO-8859-1\")\n",
        "\n",
        "# Clean up question and part IDs\n",
        "submission[\"question_id\"] = submission[\"question_id\"].astype(str).str.extract(r'(Q\\d+)')\n",
        "submission[\"part_id\"] = submission[\"part_id\"].astype(str).str.extract(r'(\\d+)')\n",
        "\n",
        "submission.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# === ✅ ANSWER DICTIONARY ===\n",
        "answers = {\n",
        "    (\"Q1\", \"1\"): \"TRUE\",\n",
        "    (\"Q1\", \"2\"): \"TRUE\",\n",
        "    (\"Q1\", \"3\"): 2688,\n",
        "\n",
        "    (\"Q2\", \"1\"): 0.002,\n",
        "    (\"Q2\", \"2\"): -0.024,\n",
        "    (\"Q2\", \"3\"): -0.008,\n",
        "\n",
        "    (\"Q3\", \"1\"): [12.786, 12.838, 12.789],  # Offers shown\n",
        "    (\"Q3\", \"2\"): [10.375, 11.389, 12.084],  # Offers clicked\n",
        "    (\"Q3\", \"3\"): \"LOW\",\n",
        "\n",
        "    (\"Q4\", \"1\"): [\n",
        "        \"760457:Unknown\", \"498907:Travel\", \"313795:Travel\", \"72053:Shopping\",\n",
        "        \"82025:Travel\", \"23311:Shopping\", \"7337:Shopping\", \"26175:Dining\",\n",
        "        \"331980:Shopping\", \"26379:Shopping\"\n",
        "    ],\n",
        "    (\"Q4\", \"2\"): 3853.782,\n",
        "    (\"Q4\", \"3\"): [\n",
        "        \"760457:0.168\", \"498907:0.153\", \"313795:0.145\", \"72053:0.140\",\n",
        "        \"82025:0.138\", \"23311:0.126\", \"7337:0.117\", \"26175:0.115\",\n",
        "        \"331980:0.111\", \"26379:0.110\"\n",
        "    ],\n",
        "\n",
        "    (\"Q5\", \"1\"): [\n",
        "        \"1686517:16.23\", \"1674697:0.45\", \"1521739:0.126\", \"1407212:0.103\",\n",
        "        \"1672300:2.194\", \"1006105:0.68\", \"1391327:0.0\", \"1077553:2.075\",\n",
        "        \"1683309:2.695\", \"1846042:1.288\", \"1500394:123.0\", \"1313065:6.0\",\n",
        "        \"1282059:0.787\", \"1598859:2.75\", \"1207550:15.666\"\n",
        "    ],\n",
        "    (\"Q5\", \"2\"): [\n",
        "        \"1686517:Shopping\", \"1674697:Shopping\", \"1521739:Travel\", \"1407212:Shopping\",\n",
        "        \"1672300:Shopping\", \"1006105:Shopping\", \"1391327:Shopping\", \"1077553:Shopping\",\n",
        "        \"1683309:Shopping\", \"1846042:Shopping\", \"1500394:Shopping\", \"1313065:Shopping\",\n",
        "        \"1282059:Shopping\", \"1598859:Shopping\", \"1207550:Shopping\"\n",
        "    ],\n",
        "    (\"Q5\", \"3\"): [\n",
        "        \"1686517:nan\", \"1674697:nan\", \"1521739:nan\", \"1407212:1.6\", \"1672300:nan\",\n",
        "        \"1006105:nan\", \"1391327:nan\", \"1077553:nan\", \"1683309:nan\", \"1846042:nan\",\n",
        "        \"1500394:nan\", \"1313065:nan\", \"1282059:nan\", \"1598859:1.25\", \"1207550:nan\"\n",
        "    ],\n",
        "\n",
        "    (\"Q6\", \"1\"): 0.047,\n",
        "    (\"Q6\", \"2\"): 0.095,\n",
        "}\n",
        "\n",
        "# === ✅ Fill in the submission file ===\n",
        "filled = 0\n",
        "row_counters = {}\n",
        "\n",
        "for idx, row in submission.iterrows():\n",
        "    q = row[\"question_id\"]\n",
        "    subq = row[\"part_id\"]\n",
        "    key = (q, subq)\n",
        "\n",
        "    if key in answers:\n",
        "        val = answers[key]\n",
        "        if isinstance(val, list):\n",
        "            if key not in row_counters:\n",
        "                row_counters[key] = 0\n",
        "            if row_counters[key] < len(val):\n",
        "                submission.at[idx, \"Answer\"] = val[row_counters[key]]\n",
        "                row_counters[key] += 1\n",
        "                filled += 1\n",
        "        else:\n",
        "            submission.at[idx, \"Answer\"] = val\n",
        "            filled += 1\n",
        "\n",
        "print(f\"✅ Successfully filled {filled} answers.\")\n",
        "\n",
        "# === ✅ Save to output ===\n",
        "output_path = \"/kaggle/working/final_submission.csv\"\n",
        "submission.to_csv(output_path, index=False)\n",
        "print(f\"📁 Submission file saved at: {output_path}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-04T08:19:07.53156Z",
          "iopub.execute_input": "2025-07-04T08:19:07.531863Z",
          "iopub.status.idle": "2025-07-04T08:19:07.559733Z",
          "shell.execute_reply.started": "2025-07-04T08:19:07.531842Z",
          "shell.execute_reply": "2025-07-04T08:19:07.55895Z"
        },
        "id": "wuaS-eKPuTAm",
        "outputId": "4e7af053-ccc1-4313-c0c0-f12e7beba423"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "✅ Successfully filled 81 answers.\n📁 Submission file saved at: /kaggle/working/final_submission.csv\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}